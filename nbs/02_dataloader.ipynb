{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataloader\n",
    "\n",
    "> API details.\n",
    "\n",
    "1. read_image(path: str, channels: int=3)\n",
    "2. clf.load_from_folder\n",
    "3. clf.load_from_csv\n",
    "4. detect.load_from_xml\n",
    "5. detect.load_from_csv\n",
    "6. detect.load_from_json\n",
    "7. detect.load_from_tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "from typing import Union\n",
    "\n",
    "from chitra.core import remove_dsstore\n",
    "from chitra.image import read_image, resize_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLF\n",
    "\n",
    "``DataLoader class for loading dataset for image classification tasks.``\n",
    "All private functions use primitive datatypes\n",
    "\n",
    "\n",
    "## clf.load_from_folder\n",
    "## clf.load_from_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_basename(path: tf.string):\n",
    "    assert isinstance(path, tf.Tensor)\n",
    "    return tf.strings.split(path, os.path.sep)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Clf(object):\n",
    "    def __init__(self):\n",
    "        self.CLASS_NAMES = None\n",
    "    \n",
    "    def _get_image_list(self, path: str):\n",
    "        \"\"\"`path`: pathlib.Path\n",
    "        Returns: list of images\n",
    "        \"\"\"\n",
    "        assert isinstance(path, str)\n",
    "        list_images = tf.data.Dataset.list_files(f'{path}/*/*')\n",
    "        return list_images\n",
    "    \n",
    "    def _process_path(self, path:str, size:Union[None, tuple] = None):\n",
    "        \"\"\"`path` :str\n",
    "        `size`: None or tuple\n",
    "        \"\"\"\n",
    "        assert isinstance(path, (str, tf.Tensor)), f'type of path is {type(path)}, expected type str'\n",
    "        img = read_image(path)\n",
    "        img = tf.py_function(resize_image, [img, (160, 160)], [tf.float32])\n",
    "        \n",
    "        label = tf.strings.split(path, os.path.sep)[-2]\n",
    "        return img, label\n",
    "\n",
    "    \n",
    "    def from_folder(self, path: Union[str, pathlib.Path]):\n",
    "        \"\"\"Load dataset from given path.\n",
    "        Args:\n",
    "            path: string, path of folder containing dataset.\n",
    "        Returns: tf.data.Dataset\n",
    "        \"\"\"\n",
    "        assert isinstance(path, (str, pathlib.Path))\n",
    "        path = pathlib.Path(path)\n",
    "        remove_dsstore(path)\n",
    "        \n",
    "        list_folders = tf.data.Dataset.list_files(str(path/'*'))\n",
    "        list_images = self._get_image_list(str(path))\n",
    "                \n",
    "        self.CLASS_NAMES = tuple(get_basename(e).numpy() for e in list_folders)\n",
    "        \n",
    "        data = list_images.map(self._process_path, num_parallel_calls=AUTOTUNE)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: (<unknown>, ()), types: (tf.float32, tf.string)>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "path = '/Users/aniketmaurya/Pictures/cats'\n",
    "\n",
    "clf = Clf()\n",
    "data = clf.from_folder(path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 160, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "for e in data.take(1): print(e[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
