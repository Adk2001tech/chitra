{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataloader\n",
    "\n",
    "> API details.\n",
    "\n",
    "> **All private functions use primitive datatypes**\n",
    "\n",
    "\n",
    "1. read_image(path: str, channels: int=3)\n",
    "2. clf.load_from_folder\n",
    "3. clf.load_from_csv\n",
    "4. detect.load_from_xml\n",
    "5. detect.load_from_csv\n",
    "6. detect.load_from_json\n",
    "7. detect.load_from_tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Union\n",
    "\n",
    "from chitra.core import remove_dsstore\n",
    "from chitra.image import read_image, resize_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_basename(path: tf.string):\n",
    "    assert isinstance(path, tf.Tensor)\n",
    "    return tf.strings.split(path, os.path.sep)[-1]\n",
    "\n",
    "\n",
    "def show_batch(data: tf.data.Dataset, limit: int, figsize: tuple = (10, 10)):\n",
    "    \"\"\"Visualize image and labels\n",
    "    \n",
    "    https://www.tensorflow.org/tutorials/load_data/images#load_using_keraspreprocessing\n",
    "    \n",
    "    Args:\n",
    "        data: tf.data.Dataset containing image, label\n",
    "        limit: number of images to display\n",
    "        figsize: size of visualization\n",
    "    Returns:\n",
    "        Displays images and labels\n",
    "    \"\"\"\n",
    "    assert isinstance(limit, int)\n",
    "    assert isinstance(figsize, tuple)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    sub_plot_size = math.ceil(limit / 2)\n",
    "\n",
    "    for i, e in enumerate(data.take(limit)):\n",
    "        image, label = e\n",
    "        image = image.numpy().astype('uint8')\n",
    "        label = label.numpy().decode()\n",
    "\n",
    "        ax = plt.subplot(sub_plot_size, sub_plot_size, i + 1)\n",
    "\n",
    "        plt.imshow(image)\n",
    "        plt.title(label.title())\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLF DLoader\n",
    "\n",
    "``DataLoader class for loading dataset for image classification tasks.``\n",
    "\n",
    "## clf.load_from_folder (TODOs)\n",
    "\n",
    "1. `__len__` method impl\n",
    "2. `image augmentation` impl\n",
    "\n",
    "## folder structure\n",
    "\n",
    "><pre>/root\n",
    "    /class1_folder\n",
    "        /img0.jpg img1.jpg img2.jpg ....\n",
    "    /class2_folder\n",
    "        /img0.jpg...</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Clf(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.CLASS_NAMES = None\n",
    "        self.data = None\n",
    "\n",
    "    def _get_image_list(self, path: str):\n",
    "        \"\"\"`path`: pathlib.Path\n",
    "        Returns: list of images\n",
    "        \"\"\"\n",
    "        assert isinstance(path, str)\n",
    "        list_images = tf.data.Dataset.list_files(f'{path}/*/*')\n",
    "        return list_images\n",
    "\n",
    "    def _process_path(self, path: str, size: Union[None, tuple] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            `path` :str\n",
    "            `size`: None or tuple\n",
    "        Returns:\n",
    "            image, label\n",
    "        \"\"\"\n",
    "        assert isinstance(path,(str, tf.Tensor)), f'type of path is {type(path)}, expected type str'\n",
    "        img = read_image(path)\n",
    "\n",
    "        # TODO: resizing should be done separately\n",
    "        # py_function will degrade performance\n",
    "        [img,] = tf.py_function(resize_image, [img, (160, 160)], [tf.float32])\n",
    "\n",
    "        label = tf.strings.split(path, os.path.sep)[-2]\n",
    "        return img, label\n",
    "\n",
    "    def from_folder(self, path: Union[str, pathlib.Path]):\n",
    "        \"\"\"Load dataset from given path.\n",
    "        Args:\n",
    "            path: string, path of folder containing dataset.\n",
    "        Returns: image, label -> tf.data.Dataset prefetched with tf.data.AUTOTUNE\n",
    "        \"\"\"\n",
    "        assert isinstance(path, (str, pathlib.Path))\n",
    "        path = pathlib.Path(path)\n",
    "        remove_dsstore(path)\n",
    "\n",
    "        list_folders = tf.data.Dataset.list_files(str(path / '*'))\n",
    "        list_images = self._get_image_list(str(path))\n",
    "\n",
    "        self.CLASS_NAMES = tuple(\n",
    "            get_basename(e).numpy().decode().title() for e in list_folders)\n",
    "\n",
    "        data = list_images.map(self._process_path, num_parallel_calls=AUTOTUNE)\n",
    "        # data = data.map(self._resize)\n",
    "\n",
    "        # data = data.prefetch(AUTOTUNE)\n",
    "        self.data = data\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "path = '/Users/aniketmaurya/Pictures/cats'\n",
    "\n",
    "clf = Clf()\n",
    "data = clf.from_folder(path)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 160, 160, 3)\n",
      "(5, 160, 160, 3)\n",
      "(5, 160, 160, 3)\n",
      "(5, 160, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "for e in data.batch(5): print(e[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect\n",
    "\n",
    "## from_xml\n",
    "### Steps:\n",
    "    . list annotations\n",
    "    . read and parse annotations\n",
    "    . read images\n",
    "    . return images and annotations\n",
    "### folder structure\n",
    "\n",
    "><pre>/root\n",
    "    /image_folder\n",
    "    /annotation_folder</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detect(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.CLASS_NAMES = None\n",
    "\n",
    "    def from_xml(self, path: Union[str, pathlib.Path]):\n",
    "        \"\"\"Load dataset from given path.\n",
    "        Args:\n",
    "            path: string, path of folder containing dataset.\n",
    "        Returns: image, label -> tf.data.Dataset prefetched with tf.data.AUTOTUNE\n",
    "        \"\"\"\n",
    "        assert isinstance(path, (str, pathlib.Path))\n",
    "        path = pathlib.Path(path)\n",
    "        remove_dsstore(path)\n",
    "\n",
    "        list_folders = tf.data.Dataset.list_files(str(path / '*'))\n",
    "        list_images = self._get_image_list(str(path))\n",
    "\n",
    "        self.CLASS_NAMES = tuple(get_basename(e).numpy() for e in list_folders)\n",
    "\n",
    "        data = list_images.map(self._process_path, num_parallel_calls=AUTOTUNE)\n",
    "        data = data.prefetch(AUTOTUNE)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
