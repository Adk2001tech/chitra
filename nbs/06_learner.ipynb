{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learner\n",
    "> API details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#hide\n",
    "# module name here\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.models import Model\n",
    "from chitra.datagenerator import Dataset\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import sys, inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_classifier(base_model_fn:callable, num_outputs, weights='imagenet', dropout=0.5, name=None):\n",
    "    base_model = base_model_fn(\n",
    "        include_top=False,\n",
    "        input_shape=(None, None, 3),\n",
    "        weights=weights,\n",
    "    )\n",
    "    model = tf.keras.Sequential(name=name)\n",
    "    model.add(base_model)\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(num_outputs, name='output'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Learner(Model):\n",
    "    _AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "            \n",
    "    def __init__(self, ds: Dataset, base_model_fn:callable, pretrained=True, **kwargs):\n",
    "        super(Learner, self).__init__()\n",
    "        self.ds = ds\n",
    "        self.total = len(ds)\n",
    "        self.NUM_CLASSES = ds.NUM_CLASSES\n",
    "        \n",
    "        weights = 'imagenet' if pretrained else None\n",
    "        \n",
    "        #self.base_model = base_model_fn.name\n",
    "        \n",
    "        self.model = create_classifier(\n",
    "            base_model_fn,\n",
    "            self.NUM_CLASSES,\n",
    "            name=kwargs.get('name', None)\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def build(self): pass\n",
    "         \n",
    "    def summary(self): return self.model.summary()\n",
    "\n",
    "    #def get_layer(name=None, index=None): return self.model(name, index)\n",
    "    \n",
    "    def compile(self, *args, **kwargs): return self.model.compile(*args, **kwargs)\n",
    "    \n",
    "    def call(self, *args, **kwargs): return self.model.call(*args, **kwargs)\n",
    "    \n",
    "    def fit(self, *args, **kwargs): return self.model.fit(*args, **kwargs)\n",
    "    \n",
    "    def warmup(self):pass\n",
    "    \n",
    "    def rescale(self, image, label):\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image = image / 127.5 - 1.0\n",
    "        return image, label\n",
    "    \n",
    "    def _get_optimizer(self,\n",
    "                       optimizer,\n",
    "                       momentum=0.9,\n",
    "                       **kwargs\n",
    "                      ):\n",
    "        if optimizer.__name__=='SGD':\n",
    "            optimizer = partial(optimizer,\n",
    "                momentum=momentum,\n",
    "                nesterov=kwargs.get('nesterov', True)\n",
    "            )\n",
    "        else:\n",
    "            optimizer = partial(optimizer,\n",
    "                momentum=momentum,\n",
    "            )\n",
    "        return optimizer\n",
    "    \n",
    "    \n",
    "    def _prepare_dl(self, bs=8, shuffle=True):\n",
    "        dl = ds.get_tf_dataset(shuffle=shuffle)\n",
    "        dl = dl.map(self.rescale, Learner._AUTOTUNE)\n",
    "        return dl.batch(bs).prefetch(Learner._AUTOTUNE)\n",
    "\n",
    "    \n",
    "    def cyclic_fit(self,\n",
    "                   epochs,\n",
    "                   batch_size,\n",
    "                   lr_range=(1e-4, 1e-2),\n",
    "                   optimizer=tf.keras.optimizers.SGD,\n",
    "                   momentum=0.9,\n",
    "                   validation_data=None,\n",
    "                   callbacks=None,\n",
    "                   *args,\n",
    "                   **kwargs\n",
    "                  ):\n",
    "        \n",
    "        self.max_lr, self.min_lr = lr_range\n",
    "        \n",
    "        step_size = 2 * len(self.ds)//batch_size\n",
    "        \n",
    "        lr_schedule = tfa.optimizers.Triangular2CyclicalLearningRate(\n",
    "                                    initial_learning_rate=lr_range[0],\n",
    "                                    maximal_learning_rate=lr_range[1],\n",
    "                                    step_size=kwargs.get('step_size', step_size),\n",
    "                                    scale_mode=kwargs.get('scale', 'cycle'))\n",
    "        \n",
    "        \n",
    "        optimizer = self._get_optimizer(optimizer, momentum=momentum)\n",
    "        optimizer = optimizer(learning_rate=lr_schedule)\n",
    "        self.model.optimizer = optimizer\n",
    "        \n",
    "        return self.model.fit(\n",
    "            self._prepare_dl(batch_size, kwargs.get('shuffle', True)),\n",
    "            validation_data=validation_data,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_filenames updated with <function load_files at 0x7f4eae8b9560>\n",
      "get_label updated with <function get_label at 0x7f4eae8b9dd0>\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "def load_files(path):\n",
    "    return glob(f'{path}/*/images/*')\n",
    "\n",
    "def get_label(path):\n",
    "    return path.split('/')[-3]\n",
    "\n",
    "\n",
    "ds = Dataset('/data/aniket/tiny-imagenet/data/tiny-imagenet-200/train', image_size=(64, 64))\n",
    "ds.update_component('get_filenames', load_files)\n",
    "ds.update_component('get_label', get_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(ds=ds, base_model_fn=tf.keras.applications.xception.Xception, name='myModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "    108/Unknown - 95s 879ms/step - loss: 10.9953"
     ]
    }
   ],
   "source": [
    "learner.cyclic_fit(5, 64, (1e-4, 1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
