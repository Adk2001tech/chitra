{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataloader\n",
    "\n",
    "> API details.\n",
    "\n",
    "1. read_image(path: str, channels: int=3)\n",
    "2. clf.load_from_folder\n",
    "3. clf.load_from_csv\n",
    "4. detect.load_from_xml\n",
    "5. detect.load_from_csv\n",
    "6. detect.load_from_json\n",
    "7. detect.load_from_tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "from typing import Union\n",
    "\n",
    "from chitra.core import remove_dsstore\n",
    "from chitra.image import read_image, resize_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLF\n",
    "\n",
    "``DataLoader class for loading dataset for image classification tasks.``\n",
    "All private functions use primitive datatypes\n",
    "\n",
    "\n",
    "## clf.load_from_folder\n",
    "## clf.load_from_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_basename(path: tf.string):\n",
    "    assert isinstance(path, tf.Tensor)\n",
    "    return tf.strings.split(path, os.path.sep)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Clf(object):\n",
    "    def __init__(self):\n",
    "        self.CLASS_NAMES = None\n",
    "    \n",
    "    def _get_image_list(self, path: str):\n",
    "        \"\"\"`path`: pathlib.Path\n",
    "        Returns: list of images\n",
    "        \"\"\"\n",
    "        assert isinstance(path, str)\n",
    "        list_images = tf.data.Dataset.list_files(f'{path}/*/*')\n",
    "        return list_images\n",
    "    \n",
    "    def _process_path(self, path:str, size:Union[None, tuple] = None):\n",
    "        \"\"\"`path` :str\n",
    "        `size`: None or tuple\n",
    "        \"\"\"\n",
    "        assert isinstance(path, (str, tf.Tensor)), f'type of path is {type(path)}, expected type str'\n",
    "        img = read_image(path)\n",
    "        img = tf.py_function(resize_image, [img, (160, 160)], [tf.float32])\n",
    "        \n",
    "        label = tf.strings.split(path, os.path.sep)[-2]\n",
    "        return img, label\n",
    "\n",
    "    \n",
    "    def from_folder(self, path: Union[str, pathlib.Path]):\n",
    "        \"\"\"Load dataset from given path.\n",
    "        Args:\n",
    "            path: string, path of folder containing dataset.\n",
    "        Returns: tf.data.Dataset\n",
    "        \"\"\"\n",
    "        assert isinstance(path, (str, pathlib.Path))\n",
    "        path = pathlib.Path(path)\n",
    "        remove_dsstore(path)\n",
    "        \n",
    "        list_folders = tf.data.Dataset.list_files(str(path/'*'))\n",
    "        list_images = self._get_image_list(str(path))\n",
    "                \n",
    "        self.CLASS_NAMES = tuple(get_basename(e).numpy() for e in list_folders)\n",
    "        \n",
    "        data = list_images.map(self._process_path, num_parallel_calls=AUTOTUNE)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: (<unknown>, ()), types: (tf.float32, tf.string)>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "clf = Clf()\n",
    "data = clf.from_folder(cats_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: id=3337, shape=(1, 160, 160, 3), dtype=float32, numpy=\n",
      "array([[[[ 43.340626,  39.340626,  27.340626],\n",
      "         [ 36.89375 ,  32.89375 ,  21.89375 ],\n",
      "         [ 35.553123,  31.553125,  22.553125],\n",
      "         ...,\n",
      "         [160.7875  , 134.7875  ,  85.7875  ],\n",
      "         [159.23438 , 133.23438 ,  82.234375],\n",
      "         [143.55313 , 120.55312 ,  50.553123]],\n",
      "\n",
      "        [[ 37.340626,  33.340626,  21.340626],\n",
      "         [ 38.021877,  34.021877,  23.021875],\n",
      "         [ 43.659374,  39.659374,  30.659374],\n",
      "         ...,\n",
      "         [151.31876 , 123.      ,  67.34062 ],\n",
      "         [151.31876 , 123.34062 ,  67.      ],\n",
      "         [143.34062 , 117.3625  ,  48.021877]],\n",
      "\n",
      "        [[ 39.765625,  35.765625,  23.765625],\n",
      "         [ 41.765625,  37.765625,  26.765625],\n",
      "         [ 40.0625  ,  36.0625  ,  27.0625  ],\n",
      "         ...,\n",
      "         [148.46875 , 118.703125,  58.703125],\n",
      "         [147.9375  , 118.171875,  58.171875],\n",
      "         [141.23438 , 111.703125,  49.      ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 61.234375,  57.234375,  46.234375],\n",
      "         [ 49.296875,  45.296875,  36.296875],\n",
      "         [ 56.53125 ,  51.53125 ,  45.53125 ],\n",
      "         ...,\n",
      "         [ 62.359375,  58.359375,  46.359375],\n",
      "         [ 42.109375,  40.109375,  27.109375],\n",
      "         [ 56.59375 ,  57.59375 ,  41.59375 ]],\n",
      "\n",
      "        [[ 42.659424,  38.659424,  29.659424],\n",
      "         [ 58.97827 ,  54.97827 ,  45.97827 ],\n",
      "         [ 39.659424,  34.659424,  28.659424],\n",
      "         ...,\n",
      "         [ 40.97827 ,  33.97827 ,  23.978271],\n",
      "         [ 59.      ,  56.      ,  39.      ],\n",
      "         [ 40.97827 ,  39.97827 ,  21.978271]],\n",
      "\n",
      "        [[ 57.340515,  53.340515,  44.340515],\n",
      "         [ 51.106323,  46.106323,  40.106323],\n",
      "         [ 48.55316 ,  43.55316 ,  38.659485],\n",
      "         ...,\n",
      "         [ 58.      ,  51.      ,  41.      ],\n",
      "         [ 47.55316 ,  44.55316 ,  25.553162],\n",
      "         [ 51.55316 ,  48.55316 ,  29.553162]]]], dtype=float32)>, <tf.Tensor: id=3338, shape=(), dtype=string, numpy=b'whitecat'>)\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "for e in data.take(1): print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=<unknown>, dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.string, name=None))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "data.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
